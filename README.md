# Supervised Machine Learning

A brief description of what this repo does and who it's for

## Overview
This repository contains the materials, notes, and resources I used during my Supervised Learning.The Learning focused on understanding the theory and practical implementation of supervised machine learning algorithms, including how they can be applied to real-world datasets.

## Table of Content 
The key topics covered include:<br>
- _Introduction to Supervised Learning:_ Basic concepts, types of learning (classification vs. regression), and key applications.
  
- _Linear Regression:_ Understanding simple and multiple linear regression, loss functions, gradient descent, and evaluation metrics (e.g., R-squared, RMSE).
  
- _Logistic Regression:_ For binary classification, the sigmoid function, decision boundaries, and evaluation (e.g., accuracy, precision, recall, F1-score).
  
- _K-Nearest Neighbors (KNN):_ Concept of instance-based learning, distance metrics (e.g., Euclidean distance), and how KNN can be used for classification and regression.
  
- _Support Vector Machines (SVM):_ Understanding hyperplanes, margins, kernel functions, and how SVMs separate data points in high-dimensional spaces.
  
- _Decision Trees and Random Forests:_ How decision trees work, Gini impurity, entropy, overfitting, and the role of random forests in reducing variance.
 
- _Naive Bayes:_ Bayes' theorem, conditional probability, and applications of Naive Bayes for text classification.
  
- _Boosting:_ Adaptive Boosting (AdaBoost), Gradient Boosting, and their role in reducing bias and variance.
  
- _Ensemble Learning:_ Bagging, boosting, stacking, and combining multiple models to improve performance.
  
- _Model Evaluation:_ Understanding overfitting and underfitting, cross-validation, and performance metrics like confusion matrices, AUC-ROC curves, and learning curves.

