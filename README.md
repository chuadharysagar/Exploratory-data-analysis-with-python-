# Supervised Machine Learning

A brief description of what this repo does and who it's for

## Overview
This repository contains the materials, notes, and resources I used during my Supervised Learning.The Learning focused on understanding the theory and practical implementation of supervised machine learning algorithms, including how they can be applied to real-world datasets.

## Table of Content 
The key topics covered include:<br>
- __Introduction to Supervised Learning:__ Basic concepts, types of learning (classification vs. regression), and key applications.
- Linear Regression: Understanding simple and multiple linear regression, loss functions, gradient descent, and evaluation metrics (e.g., R-squared, RMSE).
- Logistic Regression: For binary classification, the sigmoid function, decision boundaries, and evaluation (e.g., accuracy, precision, recall, F1-score).
- K-Nearest Neighbors (KNN): Concept of instance-based learning, distance metrics (e.g., Euclidean distance), and how KNN can be used for classification and regression.
- Support Vector Machines (SVM): Understanding hyperplanes, margins, kernel functions, and how SVMs separate data points in high-dimensional spaces.
- Decision Trees and Random Forests: How decision trees work, Gini impurity, entropy, overfitting, and the role of random forests in reducing variance.
- Naive Bayes: Bayes' theorem, conditional probability, and applications of Naive Bayes for text classification.
- Boosting: Adaptive Boosting (AdaBoost), Gradient Boosting, and their role in reducing bias and variance.
- Ensemble Learning: Bagging, boosting, stacking, and combining multiple models to improve performance.
- Model Evaluation: Understanding overfitting and underfitting, cross-validation, and performance metrics like confusion matrices, AUC-ROC curves, and learning curves.

